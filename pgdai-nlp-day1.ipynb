{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program by : Tushar B. Kute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'They told that their ages are 32, 31 and 27 respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 27]\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for word in sent.split():\n",
    "    if word.isdigit():\n",
    "        num.append(int(word))\n",
    "\n",
    "print(num)\n",
    "#print(sum(num) / len(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hello friends ! How are you ? Welcome to Pune .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct = [word for word in sent.split() if not word.isalpha()]\n",
    "len(punct) / len(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'They told that their ages are 32, 31 and 27 respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'told',\n",
       " 'that',\n",
       " 'their',\n",
       " 'ages',\n",
       " 'are',\n",
       " '32',\n",
       " ',',\n",
       " '31',\n",
       " 'and',\n",
       " '27',\n",
       " 'respectively',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "for word in word_tokenize(sent):\n",
    "    if word.isdigit():\n",
    "        num.append(int(word))\n",
    "\n",
    "#print(num)\n",
    "print(sum(num) / len(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mitu/programs/ml/nlp'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = 'Hello how are you? Welcome to Pune! Enjoy python learning.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello how are you?', 'Welcome to Pune!', 'Enjoy python learning.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segmentation\n",
    "sent_tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = 'Hello how are you?\\tWelcome to Pune!\\nEnjoy python learning.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello how are you?\tWelcome to Pune!\n",
      "Enjoy python learning.\n"
     ]
    }
   ],
   "source": [
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you?\\tWelcome',\n",
       " 'to',\n",
       " 'Pune!\\nEnjoy',\n",
       " 'python',\n",
       " 'learning.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Space tokenizer\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "tk = SpaceTokenizer()\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello how are you?', 'Welcome to Pune!\\nEnjoy python learning.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tab tokenizer\n",
    "from nltk.tokenize import TabTokenizer\n",
    "tk = TabTokenizer()\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello how are you?\\tWelcome to Pune!', 'Enjoy python learning.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Line tokenizer\n",
    "from nltk.tokenize import LineTokenizer\n",
    "tk = LineTokenizer()\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('myfile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO HOW ARE YOU?\n",
      "WELCOME TO PUNE!\n",
      "ENJOY PYTHON LEARNING.\n"
     ]
    }
   ],
   "source": [
    "for line in tk.tokenize(f.read()):\n",
    "    print(line.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Pune!',\n",
       " 'Enjoy',\n",
       " 'python',\n",
       " 'learning.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# White Space tokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Please don't make 'noise'. You aren't aware about it. We won't do it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please don't make 'noise'. You aren't aware about it. We won't do it\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'make',\n",
       " \"'noise'.\",\n",
       " 'You',\n",
       " 'are',\n",
       " \"n't\",\n",
       " 'aware',\n",
       " 'about',\n",
       " 'it.',\n",
       " 'We',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'do',\n",
       " 'it']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# White Space tokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tk = TreebankWordTokenizer()\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¤ªà¥ƒà¤¢\n"
     ]
    }
   ],
   "source": [
    "s = '\\u092A\\u0943\\u0922'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I like PythonðŸ‘‘ so muchðŸ™Œ. It is  powerfulðŸ’ª AI languageðŸ˜‡.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'like',\n",
       " 'Python',\n",
       " 'ðŸ‘‘',\n",
       " 'so',\n",
       " 'much',\n",
       " 'ðŸ™Œ',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'powerful',\n",
       " 'ðŸ’ª',\n",
       " 'AI',\n",
       " 'language',\n",
       " 'ðŸ˜‡',\n",
       " '.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# White Space tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tk = TweetTokenizer()\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Van Rossom developed Python. Mr. Van Rossom is a dutch.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Van',\n",
       " 'Rossom',\n",
       " 'developed',\n",
       " 'Python',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Van',\n",
       " 'Rossom',\n",
       " 'is',\n",
       " 'a',\n",
       " 'dutch',\n",
       " '.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Van_Rossom',\n",
       " 'developed',\n",
       " 'Python',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Van_Rossom',\n",
       " 'is',\n",
       " 'a',\n",
       " 'dutch',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# White Space tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "tk = MWETokenizer()\n",
    "tk.add_mwe(('Van','Rossom'))\n",
    "tk.tokenize(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = 'Hello how are you? Welcome to Pune! Enjoy Python learning.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('how', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('?', '.'),\n",
       " ('Welcome', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('Pune', 'NNP'),\n",
       " ('!', '.'),\n",
       " ('Enjoy', 'NNP'),\n",
       " ('Python', 'NNP'),\n",
       " ('learning', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = 'NASA was established in 1958, succeeding the National Advisory Committee for Aeronautics (NACA), to give the U.S. space development effort a distinctly civilian orientation, emphasizing peaceful applications in space science.[5][6][7] NASA has since led most American space exploration, including Project Mercury, Project Gemini, the 1968-1972 Apollo Moon landing missions, the Skylab space station, and the Space Shuttle. NASA supports the International Space Station and oversees the development of the Orion spacecraft, the Space Launch System, Commercial Crew vehicles, and the planned Lunar Gateway space station. The agency is also responsible for the Launch Services Program, which provides oversight of launch operations and countdown management for uncrewed NASA launches.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was\n",
      "established\n",
      "succeeding\n",
      "give\n",
      "emphasizing\n",
      "has\n",
      "led\n",
      "including\n",
      "landing\n",
      "supports\n",
      "oversees\n",
      "planned\n",
      "is\n",
      "provides\n"
     ]
    }
   ],
   "source": [
    "for tag in pos_tag(word_tokenize(lines)):\n",
    "    if tag[1].startswith('V') and tag[0].isalpha():\n",
    "        print(tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [tag[0] for tag in pos_tag(word_tokenize(lines)) \n",
    "         if tag[1].startswith('V') and tag[0].isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word in word_tokenize(lines):\n",
    "    if word not in string.punctuation:\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA was established in 1958 succeeding the National Advisory Committee for Aeronautics NACA to give the U.S. space development effort a distinctly civilian orientation emphasizing peaceful applications in space science 5 6 7 NASA has since led most American space exploration including Project Mercury Project Gemini the 1968-1972 Apollo Moon landing missions the Skylab space station and the Space Shuttle NASA supports the International Space Station and oversees the development of the Orion spacecraft the Space Launch System Commercial Crew vehicles and the planned Lunar Gateway space station The agency is also responsible for the Launch Services Program which provides oversight of launch operations and countdown management for uncrewed NASA launches'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['hello','world']\n",
    "\" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the wikipedia page of Indian flag and perform following analysis\n",
    "# Count total number of Words\n",
    "# Count percentage of punctuation marks\n",
    "# Print total number of lines\n",
    "# How many words are in title case?\n",
    "# Print total number of common nouns\n",
    "# Remove the numbers and print the text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
